#!/usr/bin/env python
# -*- coding: utf-8 -*-

# %%
# Imports

import pandas as pd
import numpy as np

from utils.args import getparam
from utils.yamlhandler import YamlHandler  # Configuration
from utils.generic import reorder_list

import os
import time

from fastcore.all import dict2obj

# %%
# Paths

cur_dir = os.getcwd()
parent_dir = os.path.dirname(cur_dir)

configs_path = os.path.join(parent_dir, 'config', 'Xy')

# %%
# Config name

config_name = getparam('config', 'deeplearn')
which_region = getparam('region', 'geysers')

# %%

which_data = getparam('which_data', 'train')
# which_data = getparam('which_data', 'test')
# which_data = getparam('which_data', 'test2')

# %%
# Data files

if which_region == 'geysers':
    if which_data == 'train':
        pass
    elif which_data == 'test':
        pass
    elif which_data == 'test2':
        pass
    else:
        raise ValueError('Wrong data')
else:
    raise ValueError('Wrong region')

data_file = f'orig_{which_region}_{which_data}.pkl.bz2'
prepro_file = f'Xy_{which_region}_{config_name}_{which_data}.pkl.bz2'

# %%
# Paths generated by the config name

out_path = os.path.join(parent_dir, 'dataset', 'features')
os.makedirs(out_path, exist_ok=True)

# %%
# Load of the configuration

config = dict2obj(YamlHandler.safe_load_file(
    os.path.join(configs_path, f'{config_name}.yml')))

# %%
# Opening dataframes

df: pd.DataFrame = pd.read_pickle(os.path.join(
    parent_dir, 'dataset', 'merged', data_file))

# %%
# Feature-target dataset generation

t0 = time.time()
df_Xy = df.copy()

# Rename for convenience
df_Xy = df_Xy.rename(columns={'STNM': 'station', 'EID': 'event'})
df_Xy['station'] = pd.Categorical(df_Xy['station'])
df_Xy['event'] = pd.Categorical(df_Xy['event'])

df_Xy = df_Xy.reset_index().set_index(
    ['datetime', 'event', 'station'], drop=True)

# Features
# Moment magnitude (from linear regression analysis in Sharma et al. 2013)
df_Xy['Mw'] = 0.473 + 0.9 * df_Xy['MAG']

# Hypocentre radius
df_Xy['Rhypo'] = np.sqrt(
    df_Xy['EPDST']**2 + df_Xy['DEPT']**2)

# Targets
target_cols = ['PGV', 'PGA', 'SA-0.2', 'SA-0.5', 'SA-1.0']
# Peak ground measurements (max value in horiz and vert, like in Sharma et al. 2013)
for col in target_cols:
    colname = col.split('-')[0]
    colpart = col[len(colname):]

    df_Xy[col] = df_Xy[
        [f'{colname}-N{colpart}', f'{colname}-E{colpart}']].max(axis=1)

log_targets_cols = [f'log10({target})' for target in target_cols]

df_Xy[log_targets_cols] = np.log10(df_Xy[target_cols])

# %%
# More preprocessing

outliername = 'outlier'
more_cols = [outliername]

df_Xy[outliername] = 0

config_op = config.ops[0]
for config_op in config.ops:
    if config_op.name == 'bad_events':
        if which_data not in config_op.config.which_datas:
            continue

        faulty_rm = []
        for event_rm in config_op.config.events:
            if event_rm not in df_Xy.index.get_level_values('event'):
                faulty_rm.append(event_rm)

        assert len(faulty_rm) == 0, f'Bad events to remove: {faulty_rm}'

        df_Xy.loc[df_Xy.index.get_level_values(
            'event').isin(config_op.config.events), outliername] = 1

    if config_op.name == 'include_coeff_station':
        df_coeffs_s = pd.read_csv(os.path.join(
            parent_dir, 'dataset', 'original', 'site_station_sharma_et_al'),
            index_col=0, sep='\\s+')
        df_coeffs_s = df_coeffs_s.drop(columns=['Nobs'])
        df_coeffs_s = df_coeffs_s.rename(columns={'Statio': 'station'})
        df_coeffs_s = df_coeffs_s.rename(columns={
            f's({target})': f's_MOD1({target})'
            for target in df_coeffs_s.columns})
        df_coeffs_s = df_coeffs_s.set_index('station')
        df_Xy = df_Xy.join(
            df_coeffs_s, on='station', sort=False)

        assert not df_Xy.isna().any().any(), 'There are NaNs!'

df_Xy[outliername] = df_Xy[outliername].astype('category')

print(
    f'{(df_Xy[outliername] == 1).sum()} rows are labeled '
    f' as outliers.')

if config.remove_outliers:
    df_Xy = df_Xy[df_Xy[outliername] == 0]

# %%
# Sort the columns

ordered_cols = reorder_list(
    list(df_Xy.columns),
    ['Mw', 'Rhypo'] + log_targets_cols + target_cols + more_cols)

df_Xy = df_Xy[ordered_cols]

# %%
# Saving preprocessing

df_Xy.to_pickle(os.path.join(out_path, prepro_file))

# %%
